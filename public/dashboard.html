<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Detección de Cara y Voz</title>
    <style>
        body {
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            margin: 0;
            height: 100vh;
            background-color: #f0f2f5;
        }
        video {
            border: 1px solid #ccc;
            margin-bottom: 10px;
            width: 640px;
            height: 480px;
        }
        button {
            padding: 10px 20px;
            font-size: 16px;
            margin-top: 10px;
            cursor: pointer;
        }
        canvas {
            position: absolute;
            top: 0;
            left: 0;
        }
        #message {
            margin-top: 20px;
            font-size: 20px;
            color: green;
        }
        img {
            max-width: 300px; /* Hacemos que la imagen capturada sea más pequeña */
            margin-top: 20px;
        }
    </style>
</head>
<body>

<h1>Detección de Cara y Reconocimiento de Voz</h1>
<video id="videoElement" autoplay playsinline></video>
<canvas id="canvas"></canvas>
<button id="captureButton">Capturar Foto</button>
<p id="message"></p>

<!-- Contenedor para la imagen capturada -->
<div id="capturedImageContainer"></div>

<script>
    const videoElement = document.getElementById('videoElement');
    const canvas = document.getElementById('canvas');
    const captureButton = document.getElementById('captureButton');
    const message = document.getElementById('message');
    const capturedImageContainer = document.getElementById('capturedImageContainer');
    const ctx = canvas.getContext('2d');
    let displaySize;

    // Configurar y cargar la cámara
    async function setup() {
        await startCamera();
        setupVoiceRecognition(); // Inicializamos el reconocimiento de voz
    }

    // Activar la cámara
    async function startCamera() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: 'user' }
            });
            videoElement.srcObject = stream;

            videoElement.onloadeddata = () => {
                displaySize = { width: videoElement.videoWidth, height: videoElement.videoHeight };
                canvas.width = displaySize.width;
                canvas.height = displaySize.height;
                detectFace();
            };
        } catch (err) {
            console.error('Error al acceder a la cámara: ', err);
            alert('No se pudo acceder a la cámara.');
        }
    }

    // Función para detectar la cara (simulada)
    async function detectFace() {
        const faceDetected = detectFaceInCanvas();
        
        // Dibujar el círculo de la cara en el canvas
        if (faceDetected) {
            ctx.beginPath();
            ctx.arc(faceDetected.x + faceDetected.width / 2, faceDetected.y + faceDetected.height / 2, Math.max(faceDetected.width, faceDetected.height) / 2, 0, 2 * Math.PI);
            ctx.strokeStyle = 'green'; // Color del círculo
            ctx.lineWidth = 4;
            ctx.stroke();
            ctx.closePath();

            message.textContent = '¡Cara detectada! Dile "foto" para capturar.';
        } else {
            message.textContent = 'Esperando cara...';
        }

        // Llamar a la función de detección en cada ciclo de animación
        setTimeout(detectFace, 100);
    }

    // Función rudimentaria para detectar la cara (simulada con un área cuadrada)
    function detectFaceInCanvas() {
        // Obtenemos los píxeles del video
        const width = videoElement.videoWidth;
        const height = videoElement.videoHeight;

        // Definimos un área aproximada para la cara (simulada)
        const simulatedFace = { x: width / 4, y: height / 4, width: width / 2, height: height / 2 };

        return simulatedFace;
    }

    // Captura la foto y la muestra más pequeña
    captureButton.addEventListener('click', () => {
        const dataUrl = canvas.toDataURL('image/png');
        const capturedImage = document.createElement('img');
        capturedImage.src = dataUrl;
        capturedImage.style.maxWidth = '300px'; // Aseguramos que la imagen sea más pequeña
        capturedImage.style.marginTop = '20px';
        capturedImageContainer.innerHTML = ''; // Limpiar cualquier imagen anterior
        capturedImageContainer.appendChild(capturedImage);
    });

    // Inicializar el reconocimiento de voz
    function setupVoiceRecognition() {
        const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        recognition.lang = 'es-ES'; // Configuramos el idioma a español
        recognition.continuous = false; // No escuchamos de forma continua
        recognition.interimResults = false; // No queremos resultados intermedios

        // Cuando se detecta un comando de voz
        recognition.onresult = (event) => {
            const transcript = event.results[0][0].transcript.toLowerCase();
            console.log('Reconocido:', transcript);

            if (transcript.includes('foto')) {
                // Si se dice "foto", capturamos la imagen
                captureButton.click(); 
                message.textContent = '¡Foto tomada! Reconocida con la voz.';
            }
        };

        // Iniciar la escucha
        recognition.start();
    }

    // Iniciar el proceso
    setup();
</script>

</body>
</html>
