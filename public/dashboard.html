<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Detección de Cara y Reconocimiento de Voz</title>
    <style>
        body {
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            margin: 0;
            height: 100vh;
            background-color: #f0f2f5;
        }
        video {
            border: 1px solid #ccc;
            margin-bottom: 10px;
            width: 640px;
            height: 480px;
        }
        canvas {
            position: absolute;
            top: 0;
            left: 0;
        }
        #message {
            margin-top: 20px;
            font-size: 20px;
            color: green;
        }
        #capturedImageContainer {
            margin-top: 20px;
            display: flex;
            justify-content: center;
        }
        img {
            max-width: 300px; /* Hacemos que la imagen capturada sea más pequeña */
        }
    </style>
</head>
<body>

<h1>Detección de Cara y Reconocimiento de Voz</h1>
<video id="videoElement" autoplay playsinline></video>
<p id="message">Esperando reconocimiento...</p>

<!-- Contenedor para la imagen capturada -->
<div id="capturedImageContainer"></div>

<script>
    const videoElement = document.getElementById('videoElement');
    const message = document.getElementById('message');
    const capturedImageContainer = document.getElementById('capturedImageContainer');
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d');
    let displaySize;

    // Configurar y cargar la cámara
    async function setup() {
        await startCamera();
        setupVoiceRecognition(); // Inicializamos el reconocimiento de voz
    }

    // Activar la cámara
    async function startCamera() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: 'user' }
            });
            videoElement.srcObject = stream;

            videoElement.onloadeddata = () => {
                displaySize = { width: videoElement.videoWidth, height: videoElement.videoHeight };
                canvas.width = displaySize.width;
                canvas.height = displaySize.height;
                detectFace();
            };
        } catch (err) {
            console.error('Error al acceder a la cámara: ', err);
            alert('No se pudo acceder a la cámara.');
        }
    }

    // Función para detectar la cara (simulada)
    async function detectFace() {
        const faceDetected = detectFaceInCanvas();
        
        // Llamar a la función de detección en cada ciclo de animación
        setTimeout(detectFace, 100);
    }

    // Función rudimentaria para detectar la cara (simulada con un área cuadrada)
    function detectFaceInCanvas() {
        // Obtenemos los píxeles del video
        const width = videoElement.videoWidth;
        const height = videoElement.videoHeight;

        // Definimos un área aproximada para la cara (simulada)
        const simulatedFace = { x: width / 4, y: height / 4, width: width / 2, height: height / 2 };

        return simulatedFace;
    }

    // Captura la foto y la muestra más pequeña
    function capturePhoto() {
        // Establecemos las dimensiones correctas para el canvas
        canvas.width = videoElement.videoWidth;
        canvas.height = videoElement.videoHeight;
        
        // Dibujamos el contenido del video en el canvas
        ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);

        // Convertimos el contenido del canvas a una imagen
        const dataUrl = canvas.toDataURL('image/png');

        // Creamos un nuevo elemento de imagen
        const capturedImage = document.createElement('img');
        capturedImage.src = dataUrl;
        capturedImage.style.maxWidth = '300px'; // Hacemos que la imagen sea más pequeña
        capturedImage.style.marginTop = '20px';

        // Limpiamos cualquier imagen anterior y agregamos la nueva
        capturedImageContainer.innerHTML = ''; 
        capturedImageContainer.appendChild(capturedImage);

        // Actualizamos el mensaje
        message.textContent = '¡Foto tomada!'; // Mensaje de confirmación
    }

    // Inicializar el reconocimiento de voz
    function setupVoiceRecognition() {
        const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        recognition.lang = 'es-ES'; // Configuramos el idioma a español
        recognition.continuous = false; // No escuchamos de forma continua
        recognition.interimResults = false; // No queremos resultados intermedios

        // Cuando se detecta un comando de voz
        recognition.onresult = (event) => {
            const transcript = event.results[0][0].transcript.toLowerCase();
            console.log('Reconocido:', transcript);

            if (transcript.includes('foto')) {
                // Si se dice "foto", capturamos la imagen
                capturePhoto();
                message.textContent = '¡Foto tomada! Reconocida con la voz.';
            }
        };

        // Iniciar la escucha
        recognition.start();
    }

    // Iniciar el proceso
    setup();
</script>

</body>
</html>
