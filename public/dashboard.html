<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Detección de Cara y Parpadeo</title>
    <style>
        body {
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            margin: 0;
            height: 100vh;
            background-color: #f0f2f5;
        }
        video {
            border: 1px solid #ccc;
            margin-bottom: 10px;
            width: 640px;
            height: 480px;
        }
        button {
            padding: 10px 20px;
            font-size: 16px;
            margin-top: 10px;
            cursor: pointer;
        }
        canvas {
            position: absolute;
            top: 0;
            left: 0;
        }
        #message {
            margin-top: 20px;
            font-size: 20px;
            color: green;
        }
    </style>
</head>
<body>

<h1>Detección de Cara y Parpadeo</h1>
<video id="videoElement" autoplay playsinline></video>
<canvas id="canvas"></canvas>
<button id="captureButton">Capturar Foto</button>
<p id="message"></p>

<script>
    const videoElement = document.getElementById('videoElement');
    const canvas = document.getElementById('canvas');
    const captureButton = document.getElementById('captureButton');
    const message = document.getElementById('message');
    const ctx = canvas.getContext('2d');
    let displaySize;

    // Configurar y cargar los modelos de face-api.js
    async function setup() {
        await startCamera();
    }

    // Activar la cámara
    async function startCamera() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: 'user' }
            });
            videoElement.srcObject = stream;

            videoElement.onloadeddata = () => {
                displaySize = { width: videoElement.videoWidth, height: videoElement.videoHeight };
                canvas.width = displaySize.width;
                canvas.height = displaySize.height;
                detectFace();
            };
        } catch (err) {
            console.error('Error al acceder a la cámara: ', err);
            alert('No se pudo acceder a la cámara.');
        }
    }

    // Función para detectar la cara
    async function detectFace() {
        const faceDetected = detectFaceInCanvas();
        
        // Dibujar el círculo de la cara en el canvas
        if (faceDetected) {
            ctx.beginPath();
            ctx.arc(faceDetected.x + faceDetected.width / 2, faceDetected.y + faceDetected.height / 2, Math.max(faceDetected.width, faceDetected.height) / 2, 0, 2 * Math.PI);
            ctx.strokeStyle = 'green'; // Color del círculo
            ctx.lineWidth = 4;
            ctx.stroke();
            ctx.closePath();

            message.textContent = '¡Cara detectada! Parpadea varias veces.';
        } else {
            message.textContent = 'Esperando cara...';
        }

        // Llamar a la función de detección en cada ciclo de animación
        setTimeout(detectFace, 100);
    }

    // Función rudimentaria para detectar la cara (simulada con un área cuadrada)
    function detectFaceInCanvas() {
        // Obtenemos los píxeles del video
        const width = videoElement.videoWidth;
        const height = videoElement.videoHeight;

        // Definimos un área aproximada para la cara (simulada)
        const simulatedFace = { x: width / 4, y: height / 4, width: width / 2, height: height / 2 };

        return simulatedFace;
    }

    // Configuración para capturar una foto
    captureButton.addEventListener('click', () => {
        const dataUrl = canvas.toDataURL('image/png');
        const capturedImage = document.createElement('img');
        capturedImage.src = dataUrl;
        document.body.appendChild(capturedImage);
    });

    // Iniciar el proceso
    setup();
</script>

</body>
</html>
