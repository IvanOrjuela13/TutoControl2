<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Iniciar sesión</title>
    <!-- Cargar la librería face-api.js desde CDN -->
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
    <script defer src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    <style>
        #canvas {
            position: absolute;
            left: 0;
            top: 0;
            z-index: 9;
        }
        video {
            border: 3px solid #007bff;
            border-radius: 15px;
        }
    </style>
</head>
<body>
    <h2>Inicio de sesión con reconocimiento facial</h2>
    <div>
        <video id="videoInput" width="720" height="560" autoplay muted></video>
        <canvas id="canvas"></canvas>
    </div>
    <div id="message"></div>

    <script>
        // Asegurarse de que los modelos de face-api.js estén cargados desde el CDN
        async function loadModels() {
            await faceapi.nets.ssdMobilenetv1.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/weights');
            await faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/weights');
            await faceapi.nets.faceRecognitionNet.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/weights');
            console.log("Modelos cargados desde el CDN");
        }

        async function startVideo() {
            const video = document.getElementById('videoInput');
            const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
            video.srcObject = stream;

            video.onloadedmetadata = () => {
                video.play();
                detectFace(video);
            };
        }

        // Función para detectar el rostro y realizar la verificación
        async function detectFace(video) {
            const canvas = faceapi.createCanvasFromMedia(video);
            document.body.append(canvas);

            // Establecer el canvas para dibujar las detecciones
            const displaySize = { width: video.width, height: video.height };
            faceapi.matchDimensions(canvas, displaySize);

            setInterval(async () => {
                const detections = await faceapi.detectAllFaces(video)
                    .withFaceLandmarks()
                    .withFaceDescriptors();

                canvas.clear();
                canvas.drawDetections(detections);
                canvas.drawFaceLandmarks(detections);

                // Si no se detecta ningún rostro
                if (detections.length === 0) {
                    $('#message').text('No se detectó rostro, por favor mira a la cámara');
                }

                // Si se detecta un rostro, asegurarse de verificar la distancia
                if (detections.length > 0) {
                    // Aquí puedes agregar una lógica para verificar si el rostro es el adecuado (e.g., por nombre o comparación de descriptors)
                    $('#message').text('Rostro detectado, validando...');
                    
                    // Verifica el parpadeo
                    const landmarks = detections[0].landmarks;
                    const leftEye = landmarks.getLeftEye();
                    const rightEye = landmarks.getRightEye();
                    const eyeAspectRatio = calculateEAR(leftEye, rightEye);

                    if (eyeAspectRatio < 0.25) {
                        $('#message').text('Parpadeo detectado, proceso exitoso');
                        // Aquí llamarías a tu backend para validar el inicio de sesión
                        // Por ejemplo, usando AJAX para enviar los datos al servidor
                    }
                }
            }, 100);
        }

        // Cálculo de la relación entre los ojos para detectar parpadeo
        function calculateEAR(leftEye, rightEye) {
            const leftEyeHeight = distance(leftEye[1], leftEye[5]);
            const rightEyeHeight = distance(rightEye[1], rightEye[5]);
            const eyeWidth = distance(leftEye[0], rightEye[3]);

            return (leftEyeHeight + rightEyeHeight) / (2.0 * eyeWidth);
        }

        // Calcular la distancia entre dos puntos
        function distance(p1, p2) {
            const dx = p2.x - p1.x;
            const dy = p2.y - p1.y;
            return Math.sqrt(dx * dx + dy * dy);
        }

        // Cargar los modelos y comenzar a capturar video
        loadModels().then(startVideo);
    </script>
</body>
</html>
